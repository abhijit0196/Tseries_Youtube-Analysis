# -*- coding: utf-8 -*-
"""Untitled10.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11l8LWX1Co1A_tyfLnodp7UsJrGyQwWAv
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

music_data = pd.read_csv("/content/new_music_data.csv")
music_data.head()

music_data = pd.read_csv("/content/new_music_data.csv",index_col=0)
music_data.head()

music_data.shape

music_data.info()

music_data.isnull().sum()

music_data.describe()

music_data["engagement_rate"] = (music_data["likes"] + music_data["comments_count"])/music_data["views"]
music_data.head()

music_data.describe()

top_views = music_data.nlargest(5, "views")[["title", "views"]]
top_likes = music_data.nlargest(5, "likes")[["title", "likes"]]
top_comments = music_data.nlargest(5, "comments_count")[["title", "comments_count"]]

print("\n Top 5 Videos by Views:")
print(top_views)
print("\n Top 5 Videos by Likes:")
print(top_likes)
print("\n Top 5 Videos by Comments:")
print(top_comments)

import seaborn as sns
import matplotlib.pyplot as plt

# Basic histogram
plt.figure(figsize=(6,3))
plt.hist(music_data["views"], bins=30, color="skyblue", edgecolor="black")
plt.title("Distribution of Video Views")
plt.xlabel("Views")
plt.ylabel("Frequency")
plt.show()

import numpy as np
plt.figure(figsize=(6,3))
plt.hist(np.log1p(music_data["views"].dropna().astype(int)), bins=30, color="skyblue", edgecolor="black")
plt.title("Log Distribution of Views")
plt.xlabel("Log(Views)")
plt.ylabel("Frequency")
plt.show()

plt.figure(figsize=(6,3))
plt.hist(music_data["likes"].dropna(), bins=30, color="red", edgecolor="black")
plt.title("Distribution of Likes")
plt.xlabel("Likes")
plt.ylabel("Frequency")
plt.show()

import numpy as np
plt.figure(figsize=(6,3))
plt.hist(np.log1p(music_data["likes"].dropna().astype(int)), bins=30, color="red", edgecolor="black")
plt.title("Log Distribution of Likes")
plt.xlabel("Log(Likes)")
plt.ylabel("Frequency")
plt.show()

plt.figure(figsize=(6,3))
plt.hist(music_data["comments_count"].dropna(), bins=30, color="lightgreen", edgecolor="black")
plt.title("Distribution of Comments")
plt.xlabel("Comments")
plt.ylabel("Frequency")
plt.show()

plt.figure(figsize=(6,3))
plt.hist(np.log1p(music_data["comments_count"].dropna().astype(int)), bins=30, color="lightgreen", edgecolor="black")
plt.title("Log Distribution of Comments")
plt.xlabel("Log(Comments)")
plt.ylabel("Frequency")
plt.show()

plt.figure(figsize=(6,3))

plt.boxplot(music_data["views"])
plt.title("Boxplot of Views")
plt.show()

plt.figure(figsize=(6,3))

plt.boxplot(np.log1p(music_data["views"]))
plt.title("Boxplot of Log(Views)")
plt.show()

plt.figure(figsize=(6,3))

plt.boxplot(music_data["likes"])
plt.title("Boxplot of Likes")
plt.show()

plt.figure(figsize=(6,3))

plt.boxplot(np.log1p(music_data["likes"]))

plt.title("Boxplot of Log(likes)")
plt.show()

plt.figure(figsize=(6,3))

plt.boxplot(music_data["comments_count"])
plt.title("Boxplot of Comments_Count")
plt.show()

plt.figure(figsize=(6,3))

plt.boxplot(np.log1p(music_data["comments_count"]))
plt.title("Boxplot of Log(Comments_Count)")
plt.show()

import numpy as np

# Engagement rate = (likes + comments) / views
music_data["engagement_rate"] = (music_data["likes"] + music_data["comments_count"]) / music_data["views"]

desc_stats = music_data[["views","likes","comments_count","engagement_rate"]].agg(["mean","median","std"])
print(desc_stats)

import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(8,6))
sns.heatmap(music_data[["views","likes","comments_count","duration"]].corr(),
            annot=True, cmap="coolwarm", fmt=".2f")
plt.title("Correlation Matrix")
plt.show()

fig, axes = plt.subplots(2, 2, figsize=(8,4))

# Histogram - Views
sns.histplot(music_data["views"], bins=30, ax=axes[0,0], color="skyblue")
axes[0,0].set_title("Views Distribution")

# Histogram - Log(views)
sns.histplot(np.log1p(music_data["views"]), bins=30, ax=axes[0,1], color="lightgreen")
axes[0,1].set_title("Log(Views) Distribution")

# Boxplot - Views
sns.boxplot(y=music_data["views"], ax=axes[1,0], color="skyblue")
axes[1,0].set_title("Views Boxplot")

# Boxplot - Log(views)
sns.boxplot(y=np.log1p(music_data["views"]), ax=axes[1,1], color="lightgreen")
axes[1,1].set_title("Log(Views) Boxplot")

plt.tight_layout()
plt.show()

fig, axes = plt.subplots(2, 2, figsize=(8,4))

sns.histplot(music_data["likes"], bins=30, ax=axes[0,0], color="red")
axes[0,0].set_title("likes Distribution")

# Histogram - Log(views)
sns.histplot(np.log1p(music_data["likes"]), bins=30, ax=axes[0,1], color="lightgreen")
axes[0,1].set_title("Log(likes) Distribution")

# Boxplot - Views
sns.boxplot(y=music_data["likes"], ax=axes[1,0], color="red")
axes[1,0].set_title("Views Boxplot")

# Boxplot - Log(views)
sns.boxplot(y=np.log1p(music_data["likes"]), ax=axes[1,1], color="lightgreen")
axes[1,1].set_title("Log(likes) Boxplot")

plt.tight_layout()
plt.show()

fig, axes = plt.subplots(2, 2, figsize=(8,4))

# Histogram - Comments
sns.histplot(music_data["comments_count"], bins=30, ax=axes[0,0], color="salmon")
axes[0,0].set_title("Comments Distribution")

# Histogram - Log(Comments)
sns.histplot(np.log1p(music_data["comments_count"]), bins=30, ax=axes[0,1], color="orange")
axes[0,1].set_title("Log(Comments) Distribution")

# Boxplot - Comments
sns.boxplot(y=music_data["comments_count"], ax=axes[1,0], color="salmon")
axes[1,0].set_title("Comments Boxplot")

# Boxplot - Log(Comments)
sns.boxplot(y=np.log1p(music_data["comments_count"]), ax=axes[1,1], color="orange")
axes[1,1].set_title("Log(Comments) Boxplot")

plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt

# Ensure publishedAt is datetime
music_data["publishedAt"] = pd.to_datetime(music_data["publishedAt"])

# Daily average engagement
engagement_over_time = music_data.groupby(music_data["publishedAt"].dt.date)["engagement_rate"].mean()

# 7-day moving average
rolling_engagement = engagement_over_time.rolling(window=7).mean()

# Plot
plt.figure(figsize=(12,4))
plt.plot(engagement_over_time.index, engagement_over_time.values, marker="o", color="gray", label="Daily Engagement")
plt.plot(rolling_engagement.index, rolling_engagement.values, color="purple", linewidth=2, label="7-Day Moving Average")
plt.title("Engagement Rate Over Time (with 7-Day Moving Avg)")
plt.xlabel("Date")
plt.ylabel("Engagement Rate")
plt.xticks(rotation=45)
plt.legend()
plt.grid(True, linestyle="--", alpha=0.6)
plt.show()

from wordcloud import WordCloud

# Combine all titles
text_titles = " ".join(music_data["title"].dropna())

# Generate wordcloud
wc_titles = WordCloud(width=800, height=400, background_color="white", colormap="inferno").generate(text_titles)

plt.figure(figsize=(12,4))
plt.imshow(wc_titles, interpolation="bilinear")
plt.axis("off")
plt.title("Frequent Words in Video Titles")
plt.show()

# Combine descriptions
text_desc = " ".join(music_data["description"].dropna().astype(str))

wc_desc = WordCloud(width=800, height=400, background_color="white", colormap="plasma").generate(text_desc)

plt.figure(figsize=(12,4))
plt.imshow(wc_desc, interpolation="bilinear")
plt.axis("off")
plt.title("Frequent Words in Video Descriptions")
plt.show()

import ast
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Step 1: Convert stringified list into actual list
def safe_parse(x):
    if isinstance(x, str):
        try:
            val = ast.literal_eval(x)
            return val if isinstance(val, list) else [val]
        except:
            return []
    elif isinstance(x, list):
        return x
    else:
        return []

music_data["tags"] = music_data["tags"].apply(safe_parse)

# Step 2: Flatten tags with engagement
tag_engagement = {}

for idx, row in music_data.iterrows():
    tags = row["tags"] if isinstance(row["tags"], list) else []
    for tag in tags:
        if tag not in tag_engagement:
            tag_engagement[tag] = []
        if not np.isnan(row["engagement_rate"]):   # skip NaN
            tag_engagement[tag].append(row["engagement_rate"])

# Step 3: Average engagement per tag
tag_avg = {k: np.mean(v) for k, v in tag_engagement.items() if len(v) > 0}

# Step 4: Get top 10 tags
top_tags = dict(sorted(tag_avg.items(), key=lambda x: x[1], reverse=True)[:10])

# Step 5: Plot
plt.figure(figsize=(10, 4))
sns.barplot(x=list(top_tags.keys()), y=list(top_tags.values()), palette="coolwarm")
plt.title("Top Tags by Engagement Rate")
plt.xlabel("Tag")
plt.ylabel("Avg Engagement Rate")
plt.xticks(rotation=45, ha="right")
plt.show()

music_data.columns

music_data["engagement_rate"] = (
    (music_data["likes"] + music_data["comments_count"]) / music_data["views"]
)



import seaborn as sns
import matplotlib.pyplot as plt

corr = music_data[["views","likes","comments_count","engagement_rate","duration"]].corr()

plt.figure(figsize=(8,6))
sns.heatmap(corr, annot=True, cmap="coolwarm", fmt=".2f")
plt.title("Correlation Heatmap")
plt.show()

from scipy.stats import ttest_ind

short_videos = music_data[music_data["duration"] <= 300]["engagement_rate"]   # ≤5 min
long_videos  = music_data[music_data["duration"] > 300]["engagement_rate"]

t_stat, p_val = ttest_ind(short_videos.dropna(), long_videos.dropna())

print("T-test: Video Length vs Engagement")
print("t-statistic:", round(t_stat, 3))
print("p-value:", round(p_val, 5))

import re
import nltk
from nltk.sentiment.vader import SentimentIntensityAnalyzer
import seaborn as sns
import matplotlib.pyplot as plt

# Download VADER lexicon
nltk.download("vader_lexicon")

# Init analyzer
sia = SentimentIntensityAnalyzer()

# Clean text function
def clean_text(text):
    if pd.isnull(text):
        return ""
    text = text.lower()
    text = re.sub(r"http\S+|www\S+|https\S+", "", text)  # remove urls
    text = re.sub(r"[^\w\s]", "", text)  # remove punctuation
    return text

# Convert tags to string
def tags_to_string(x):
    if isinstance(x, list):
        return " ".join(map(str, x))
    elif pd.isnull(x):
        return ""
    else:
        return str(x)

music_data["tags_text"] = music_data["tags"].apply(tags_to_string)

# Combine text
music_data["text_data"] = (
    music_data["title"].fillna("") + " " +
    music_data["description"].fillna("") + " " +
    music_data["tags_text"].fillna("")
).apply(clean_text)

# Sentiment scoring
music_data["sentiment"] = music_data["text_data"].apply(lambda x: sia.polarity_scores(x)["compound"])

# Label sentiment
music_data["sentiment_label"] = music_data["sentiment"].apply(
    lambda x: "positive" if x > 0.05 else ("negative" if x < -0.05 else "neutral")
)

# Plot distribution
plt.figure(figsize=(6,4))
sns.countplot(x="sentiment_label", data=music_data, palette="coolwarm")
plt.title("Sentiment Distribution (Title + Description + Tags)")
plt.xlabel("Sentiment")
plt.ylabel("Count")
plt.show()

# --- Engagement Rate correlation with Sentiment ---
music_data["engagement_rate"] = (
    (music_data["likes"] + music_data["comments_count"]) / music_data["views"].replace(0, 1)
)

sent_corr = music_data[["sentiment", "engagement_rate"]].corr().iloc[0,1]
print("Correlation between Sentiment Score and Engagement Rate:", round(sent_corr, 3))

# Boxplot of engagement vs sentiment label
plt.figure(figsize=(6,4))
sns.boxplot(x="sentiment_label", y="engagement_rate", data=music_data, palette="Set2")
plt.title("Engagement Rate by Sentiment Category")
plt.show()

from scipy.stats import f_oneway

# Split engagement rates by sentiment category
pos_eng = music_data[music_data["sentiment_label"] == "positive"]["engagement_rate"].dropna()
neu_eng = music_data[music_data["sentiment_label"] == "neutral"]["engagement_rate"].dropna()
neg_eng = music_data[music_data["sentiment_label"] == "negative"]["engagement_rate"].dropna()

# ANOVA test
f_stat, p_val = f_oneway(pos_eng, neu_eng, neg_eng)

print("ANOVA Test: Engagement Rate across Sentiment Categories")
print("F-statistic:", round(f_stat, 3))
print("p-value:", round(p_val, 5))

# Visualize with boxplot
plt.figure(figsize=(6,4))
sns.boxplot(x="sentiment_label", y="engagement_rate", data=music_data, palette="Set2")
plt.title("Engagement Rate by Sentiment Category")
plt.show()

# ml

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score

# 1. Load dataset
df = pd.read_csv("new_music_data.csv")

# 2. Features & Target (फक्त numerical निवडले)
X = df[['categoryId', 'duration', 'likes', 'comments_count']]
y = df['views']

# 3. Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 4. Model
rf = RandomForestRegressor(n_estimators=200, random_state=42)
rf.fit(X_train, y_train)

# 5. Predictions
y_pred = rf.predict(X_test)

# 6. Evaluation
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

print(" RMSE:", rmse)
print(" R² Score:", r2)

# using log
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score

# 1. Load dataset
df = pd.read_csv("new_music_data.csv")

# 2. Features & Target
X = df[['categoryId', 'duration', 'likes', 'comments_count']]

# 🎯 Target ला log-transform केलं
y = np.log1p(df['views'])   # log(views + 1)

# 3. Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 4. Model
rf = RandomForestRegressor(n_estimators=200, random_state=42)
rf.fit(X_train, y_train)

# 5. Predictions (log-scale वर)
y_pred_log = rf.predict(X_test)

# 6. Evaluation (log-scale वर)
rmse_log = np.sqrt(mean_squared_error(y_test, y_pred_log))
r2_log = r2_score(y_test, y_pred_log)

print("Log-RMSE:", rmse_log)
print("Log R² Score:", r2_log)

# 7. Predictions परत original scale मध्ये
y_pred = np.expm1(y_pred_log)   # reverse log1p

import pandas as pd
import numpy as np
import ast
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score

# ------------------------
# Load Dataset
# ------------------------
df = pd.read_csv("new_music_data.csv")

# ------------------------
# Feature Engineering
# ------------------------

# Title length
df['title_length'] = df['title'].astype(str).apply(len)

# Description length
df['description_length'] = df['description'].astype(str).apply(len)

# Tags count (safe parsing)
def count_tags(x):
    try:
        return len(ast.literal_eval(x))
    except:
        return 0

df['tags_count'] = df['tags'].astype(str).apply(count_tags)

# Published date → weekday & hour
df['publishedAt'] = pd.to_datetime(df['publishedAt'], errors='coerce')
df['publish_weekday'] = df['publishedAt'].dt.weekday
df['publish_hour'] = df['publishedAt'].dt.hour

# Ratios
df['likes_per_view'] = df['likes'] / (df['views'] + 1)
df['comments_per_view'] = df['comments_count'] / (df['views'] + 1)

# ------------------------
# Features & Target
# ------------------------
X = df[['duration', 'likes', 'comments_count',
        'title_length', 'description_length', 'tags_count',
        'publish_weekday', 'publish_hour',
        'likes_per_view', 'comments_per_view']]

y = df['views']

# ------------------------
# Train-Test Split
# ------------------------
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# ------------------------
# Model Training
# ------------------------
rf = RandomForestRegressor(n_estimators=200, random_state=42)
rf.fit(X_train, y_train)

# Predictions
y_pred = rf.predict(X_test)

# ------------------------
# Evaluation
# ------------------------
print(" RMSE:", np.sqrt(mean_squared_error(y_test, y_pred)))
print(" R² Score:", r2_score(y_test, y_pred))

# log vaprun
import pandas as pd
import numpy as np
import ast
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt

# ------------------------
# Load Dataset
# ------------------------
df = pd.read_csv("new_music_data.csv")

# ------------------------
# Feature Engineering
# ------------------------

# Title length
df['title_length'] = df['title'].astype(str).apply(len)

# Description length
df['description_length'] = df['description'].astype(str).apply(len)

# Tags count (safe parsing)
def count_tags(x):
    try:
        return len(ast.literal_eval(x))
    except:
        return 0

df['tags_count'] = df['tags'].astype(str).apply(count_tags)

# Published date → weekday & hour
df['publishedAt'] = pd.to_datetime(df['publishedAt'], errors='coerce')
df['publish_weekday'] = df['publishedAt'].dt.weekday
df['publish_hour'] = df['publishedAt'].dt.hour

# Ratios
df['likes_per_view'] = df['likes'] / (df['views'] + 1)
df['comments_per_view'] = df['comments_count'] / (df['views'] + 1)

# ------------------------
# Features & Target
# ------------------------
X = df[['duration', 'likes', 'comments_count',
        'title_length', 'description_length', 'tags_count',
        'publish_weekday', 'publish_hour',
        'likes_per_view', 'comments_per_view']]

# 🎯 Log-transform target
y = np.log1p(df['views'])   # log(views + 1)

# ------------------------
# Train-Test Split
# ------------------------
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# ------------------------
# Model Training
# ------------------------
rf = RandomForestRegressor(n_estimators=200, random_state=42)
rf.fit(X_train, y_train)

# Predictions (log-scale)
y_pred_log = rf.predict(X_test)

# ------------------------
# Evaluation (log-scale)
# ------------------------
rmse_log = np.sqrt(mean_squared_error(y_test, y_pred_log))
r2_log = r2_score(y_test, y_pred_log)

print("Log-RMSE:", rmse_log)
print("Log R² Score:", r2_log)

# ------------------------
# Convert predictions back to original scale
# ------------------------
y_pred_original = np.expm1(y_pred_log)

import pandas as pd
import numpy as np
import ast
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
import xgboost as xgb

# ------------------------
# Load Dataset
# ------------------------
df = pd.read_csv("new_music_data.csv")

# ------------------------
# Feature Engineering
# ------------------------
df['title_length'] = df['title'].astype(str).apply(len)
df['description_length'] = df['description'].astype(str).apply(len)

def count_tags(x):
    try:
        return len(ast.literal_eval(x))
    except:
        return 0
df['tags_count'] = df['tags'].astype(str).apply(count_tags)

df['publishedAt'] = pd.to_datetime(df['publishedAt'], errors='coerce')
df['publish_weekday'] = df['publishedAt'].dt.weekday
df['publish_hour'] = df['publishedAt'].dt.hour

df['likes_per_view'] = df['likes'] / (df['views'] + 1)
df['comments_per_view'] = df['comments_count'] / (df['views'] + 1)

# ------------------------
# Features & Target
# ------------------------
X = df[['duration', 'likes', 'comments_count',
        'title_length', 'description_length', 'tags_count',
        'publish_weekday', 'publish_hour',
        'likes_per_view', 'comments_per_view']]

# Log-transform target
y = np.log1p(df['views'])

# ------------------------
# Train-Test Split
# ------------------------
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# ------------------------
# Random Forest Model
# ------------------------
rf = RandomForestRegressor(n_estimators=200, random_state=42)
rf.fit(X_train, y_train)
y_pred_rf_log = rf.predict(X_test)
rmse_rf_log = np.sqrt(mean_squared_error(y_test, y_pred_rf_log))
r2_rf_log = r2_score(y_test, y_pred_rf_log)

# ------------------------
# XGBoost Model
# ------------------------
xgb_model = xgb.XGBRegressor(
    n_estimators=200, learning_rate=0.1, max_depth=5, random_state=42
)
xgb_model.fit(X_train, y_train)
y_pred_xgb_log = xgb_model.predict(X_test)
rmse_xgb_log = np.sqrt(mean_squared_error(y_test, y_pred_xgb_log))
r2_xgb_log = r2_score(y_test, y_pred_xgb_log)

# ------------------------
# Results
# ------------------------
print("Random Forest (Log) RMSE:", rmse_rf_log)
print("Random Forest (Log) R² :", r2_rf_log)
print("XGBoost (Log) RMSE:", rmse_xgb_log)
print("XGBoost (Log) R² :", r2_xgb_log)

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
import ast

# ------------------------
# Load Dataset
# ------------------------
df = pd.read_csv("new_music_data.csv")

# ------------------------
# Feature Engineering
# ------------------------
df['title_length'] = df['title'].astype(str).apply(len)
df['description_length'] = df['description'].astype(str).apply(len)

def count_tags(x):
    try:
        return len(ast.literal_eval(x))
    except:
        return 0
df['tags_count'] = df['tags'].astype(str).apply(count_tags)

df['publishedAt'] = pd.to_datetime(df['publishedAt'], errors='coerce')
df['publish_weekday'] = df['publishedAt'].dt.weekday
df['publish_hour'] = df['publishedAt'].dt.hour

df['likes_per_view'] = df['likes'] / (df['views'] + 1)
df['comments_per_view'] = df['comments_count'] / (df['views'] + 1)

# ------------------------
# Features & Target
# ------------------------
X = df[['duration', 'likes', 'comments_count',
        'title_length', 'description_length', 'tags_count',
        'publish_weekday', 'publish_hour',
        'likes_per_view', 'comments_per_view']]

# Log-transform target
y = np.log1p(df['views'])

# ------------------------
# Train-Test Split
# ------------------------
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# ------------------------
# Linear Regression Model
# ------------------------
lr = LinearRegression()
lr.fit(X_train, y_train)
y_pred_log = lr.predict(X_test)

# ------------------------
# Evaluation (log-scale)
# ------------------------
rmse_log = np.sqrt(mean_squared_error(y_test, y_pred_log))
r2_log = r2_score(y_test, y_pred_log)

print("Linear Regression (Log) RMSE:", rmse_log)
print("Linear Regression (Log) R² Score:", r2_log)



import pandas as pd
import numpy as np
import ast
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
import matplotlib.pyplot as plt

# ------------------------
# Load Dataset
# ------------------------
df = pd.read_csv("new_music_data.csv")

# ------------------------
# Feature Engineering
# ------------------------
df['title_length'] = df['title'].astype(str).apply(len)
df['description_length'] = df['description'].astype(str).apply(len)

def count_tags(x):
    try:
        return len(ast.literal_eval(x))
    except:
        return 0
df['tags_count'] = df['tags'].astype(str).apply(count_tags)

df['publishedAt'] = pd.to_datetime(df['publishedAt'], errors='coerce')
df['publish_weekday'] = df['publishedAt'].dt.weekday
df['publish_hour'] = df['publishedAt'].dt.hour

df['likes_per_view'] = df['likes'] / (df['views'] + 1)
df['comments_per_view'] = df['comments_count'] / (df['views'] + 1)

# ------------------------
# Features & Target
# ------------------------
X = df[['duration', 'likes', 'comments_count',
       'title_length', 'description_length', 'tags_count',
       'publish_weekday', 'publish_hour',
       'likes_per_view', 'comments_per_view']]
y = np.log1p(df['views'])

# ------------------------
# Train-Test Split
# ------------------------
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# ------------------------
# Train Random Forest
# ------------------------
rf = RandomForestRegressor(n_estimators=200, random_state=42)
rf.fit(X_train, y_train)

# ------------------------
# Feature Importance
# ------------------------
importances = rf.feature_importances_
features = X.columns
indices = np.argsort(importances)[::-1]

# ------------------------
# Plot Bar Chart
# ------------------------
plt.figure(figsize=(10,6))
plt.bar(range(len(importances)), importances[indices], color='skyblue', edgecolor='black')
plt.xticks(range(len(importances)), features[indices], rotation=45, ha='right')
plt.title("Random Forest Feature Importance (Views Prediction)")
plt.show()

import pandas as pd
import numpy as np
import ast
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
import matplotlib.pyplot as plt

# ------------------------
# Load Dataset
# ------------------------
df = pd.read_csv("new_music_data.csv")

# ------------------------
# Feature Engineering
# ------------------------
df['title_length'] = df['title'].astype(str).apply(len)
df['description_length'] = df['description'].astype(str).apply(len)

def count_tags(x):
    try:
        return len(ast.literal_eval(x))
    except:
        return 0
df['tags_count'] = df['tags'].astype(str).apply(count_tags)

df['publishedAt'] = pd.to_datetime(df['publishedAt'], errors='coerce')
df['publish_weekday'] = df['publishedAt'].dt.weekday
df['publish_hour'] = df['publishedAt'].dt.hour

df['likes_per_view'] = df['likes'] / (df['views'] + 1)
df['comments_per_view'] = df['comments_count'] / (df['views'] + 1)

# ------------------------
# Features & Target
# ------------------------
X = df[['duration', 'likes', 'comments_count',
       'title_length', 'description_length', 'tags_count',
       'publish_weekday', 'publish_hour',
       'likes_per_view', 'comments_per_view']]
y = np.log1p(df['views'])

# ------------------------
# Train-Test Split
# ------------------------
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# ------------------------
# Train Random Forest
# ------------------------
rf = RandomForestRegressor(n_estimators=200, random_state=42)
rf.fit(X_train, y_train)

# ------------------------
# Feature Importance
# ------------------------
importances = rf.feature_importances_
features = X.columns
indices = np.argsort(importances)[::-1]

# ------------------------
# Plot Bar Chart with Labels
# ------------------------
plt.figure(figsize=(10,6))
bars = plt.bar(range(len(importances)), importances[indices]*100, color='skyblue', edgecolor='black')
plt.xticks(range(len(importances)), features[indices], rotation=45, ha='right')
plt.ylabel("Importance (%)")
plt.title("Random Forest Feature Importance (Views Prediction)")

# Add importance labels on top of bars
for bar in bars:
    height = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2.0, height, f'{height:.1f}%', ha='center', va='bottom', fontsize=9)

plt.tight_layout()
plt.show()





